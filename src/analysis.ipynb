{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'label', u'sen1', u'sen2']\n",
      "[u'label', u'sen1', u'sen2']\n",
      "------------------------------------------------------------\n",
      "training part\n",
      "(352366, 32, 32, 8)\n",
      "(352366, 32, 32, 10)\n",
      "(352366, 17)\n",
      "------------------------------------------------------------\n",
      "validation part\n",
      "(24119, 32, 32, 8)\n",
      "(24119, 32, 32, 10)\n",
      "(24119, 17)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "### to change according to your machine\n",
    "base_dir = os.path.expanduser(\"data/tum\")\n",
    "path_training = os.path.join(base_dir, 'training.h5')\n",
    "path_validation = os.path.join(base_dir, 'validation.h5')\n",
    "\n",
    "fid_training = h5py.File(path_training,'r')\n",
    "fid_validation = h5py.File(path_validation,'r')\n",
    "\n",
    "## we can have a look at which keys are stored in the file\n",
    "## you will get the return [u'label', u'sen1', u'sen2']\n",
    "## sen1 and sen2 means the satellite images\n",
    "print fid_training.keys()\n",
    "print fid_validation.keys()\n",
    "\n",
    "### get s1 image channel data\n",
    "### it is not really loaded into memory. only the indexes have been loaded.\n",
    "print \"-\" * 60\n",
    "print \"training part\"\n",
    "s1_training = fid_training['sen1']\n",
    "print s1_training.shape\n",
    "s2_training = fid_training['sen2']\n",
    "print s2_training.shape\n",
    "label_training = fid_training['label']\n",
    "print label_training.shape\n",
    "\n",
    "print \"-\" * 60\n",
    "print \"validation part\"\n",
    "s1_validation = fid_validation['sen1']\n",
    "print s1_validation.shape\n",
    "s2_validation = fid_validation['sen2']\n",
    "print s2_validation.shape\n",
    "label_validation = fid_validation['label']\n",
    "print label_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute the quantity for each col\n",
    "label_qty = np.sum(label_training, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/matplotlib/collections.py:548: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self._edgecolors == 'face':\n"
     ]
    }
   ],
   "source": [
    "# visualization, plot the first pair of Sentinel-1 and Sentinel-2 patches of training.h5\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(label_qty)\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(10*np.log10(s1_training[0,:,:,4]),cmap=plt.cm.get_cmap('gray'));\n",
    "plt.colorbar()\n",
    "plt.title('Sentinel-1')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(s2_training[0,:,:,1],cmap=plt.cm.get_cmap('gray'));\n",
    "plt.colorbar()\n",
    "plt.title('Sentinel-2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 0/352366\n"
     ]
    }
   ],
   "source": [
    "### simple classification example\n",
    "### Training part\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "train_s1 = s1_training\n",
    "train_s2 = s2_training\n",
    "train_label = label_training\n",
    "clf = SGDClassifier()\n",
    "\n",
    "train_y = np.argmax(train_label, axis=1)\n",
    "classes = list(set(train_y))\n",
    "batch_size = 100000\n",
    "n_samples = train_s1.shape[0]\n",
    "\n",
    "for i in range(0, n_samples, batch_size):\n",
    "    ## this is an idea for batch training\n",
    "    ## you can relpace this loop for deep learning methods\n",
    "    print(\"done %d/%d\" % (i, n_samples))\n",
    "    start_pos = i\n",
    "    end_pos = min(i + batch_size, n_samples)\n",
    "    train_s1_batch = np.asarray(train_s1[start_pos:end_pos, :, :, :])\n",
    "    train_s2_batch = np.asarray(train_s2[start_pos:end_pos, :, :, :])\n",
    "    cur_batch_size = train_s2_batch.shape[0]\n",
    "    train_s1_batch = train_s1_batch.reshape((cur_batch_size, -1))\n",
    "    train_s2_batch = train_s2_batch.reshape((cur_batch_size, -1))\n",
    "    train_X_batch = np.hstack([train_s1_batch, train_s2_batch])\n",
    "    label_batch = train_y[start_pos:end_pos]\n",
    "    clf.partial_fit(train_X_batch, label_batch, classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make a prediction on validation\n",
    "pred_y = []\n",
    "train_val_y = np.argmax(label_validation, axis=1)\n",
    "batch_size = 10000\n",
    "n_val_samples = s2_validation.shape[0]\n",
    "for i in range(0, n_val_samples, batch_size):\n",
    "    start_pos = i\n",
    "    end_pos = min(i + batch_size, n_val_samples)\n",
    "    val_s1_batch = np.asarray(s1_validation[start_pos:end_pos, :, :, :])\n",
    "    val_s2_batch = np.asarray(s2_validation[start_pos:end_pos, :, :, :])\n",
    "    cur_batch_size = val_s2_batch.shape[0]\n",
    "    val_s1_batch = val_s1_batch.reshape((cur_batch_size, -1))\n",
    "    val_s2_batch = val_s2_batch.reshape((cur_batch_size, -1))\n",
    "    val_X_batch = np.hstack([val_s1_batch, val_s2_batch])\n",
    "    tmp_pred_y = clf.predict(val_X_batch)\n",
    "    pred_y.append(tmp_pred_y)\n",
    "pred_y = np.hstack(pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.06      0.07      0.07       256\n",
      "          1       0.07      0.06      0.07      1254\n",
      "          2       0.04      0.04      0.04      2353\n",
      "          3       0.08      0.13      0.10       849\n",
      "          4       0.04      0.00      0.00       757\n",
      "          5       0.16      0.02      0.03      1906\n",
      "          6       0.00      0.00      0.00       474\n",
      "          7       0.24      0.46      0.32      3395\n",
      "          8       0.20      0.01      0.02      1914\n",
      "          9       0.10      0.06      0.08       860\n",
      "         10       0.67      0.58      0.62      2287\n",
      "         11       0.02      0.01      0.01       382\n",
      "         12       0.00      0.00      0.00      1202\n",
      "         13       0.45      0.28      0.35      2747\n",
      "         14       0.01      0.00      0.01       202\n",
      "         15       0.06      0.30      0.10       672\n",
      "         16       0.53      0.90      0.67      2609\n",
      "\n",
      "avg / total       0.25      0.28      0.24     24119\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print classification_report(train_val_y, pred_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}